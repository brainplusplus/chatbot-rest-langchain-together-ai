
# ChatBot Python using LangChain and Together AI

A sample project (ChatBot) REST API built with Python using LangChain and Together AI


## Installation

- Clone this Project
- [Download and Install Python (3.x) ](https://www.python.org/downloads/)
- [Install Pip](https://monovm.com/blog/how-to-install-pip-on-windows-linux/)
- Download and Install your favorite IDE ( Visual Studio Code, PyCharm)
- Install VirtualEnv
```bash
  pip install virtualenv
```
- Create VirtualEnv
```bash
  virtualenv venv
```
- If using windows, Activate VirtualEnv (Windows)
```bash
  venv\Scripts\activate 
```
- If using linux, Activate VirtualEnv (Linux)
```bash
  ./venv/Scripts/activate
```
- Install Dependencies
```bash
pip install -r requirements.txt
```
- Register account in [together AI](https://api.together.xyz/signup) and get API Key  
- Set Together API in Environtment Variable
- if using windows
```bash
set TOGETHER_API_KEY=your_api_key 
```
- if using linux
```bash
export TOGETHER_API_KEY=your_api_key
```

- Run Web API (with Swagger UI), with following command
```bash
uvicorn main:app --host 0.0.0.0 --port 8000   
```
- Open Swagger UI using browser in http://localhost:8000/docs
## Running Tests

Set Together API in Environtment Variable
- if using windows
```bash
set TOGETHER_API_KEY=your_api_key 

set TOGETHER_API_KEY_TEMP=your_api_key 

```
- if using linux
```bash
export TOGETHER_API_KEY=your_api_key

export TOGETHER_API_KEY_TEMP=your_api_key
```

Notes : in testing, we need duplicate value for  `TOGETHER_API_KEY` to `TOGETHER_API_KEY_TEMP` due to manipulate `TOGETHER_API_KEY` in tests, in runtime test `TOGETHER_API_KEY` will be change with false api key, because together ai library (langchain-together) read api key from Environtment Variable

To run tests, run the following command

```bash
  pytest
```


## API Reference

#### Get Answer from Chatbot
You can get answer from chatbot

```http
  POST /answer_question
```

| Parameter | Type     | Is Required                | Description                |
| :-------- | :------- | :------------------------- | :----------- |
| `question` | `string` of question | **Yes**. | Question/sentence |
| `temperature` | `integer` of question | No. | Default value : 0.7 |
| `max_tokens` | `string` of question | No. | Default value : 128 |
| `top_k` | `string` of question | No. | Default value : 50 |



#### Temperature: 
In the context of text generation, temperature controls the degree of randomness or creativity in the generated text. 

Higher temperature values (e.g., 0.8 or 1.0) result in more diverse and creative output, as the probability distribution becomes more even. 

Lower temperature values (e.g., 0.2 or 0.5) produce more conservative and predictable text, as the probability of word choices becomes more focused.

#### Max_tokens:

This parameter allows you to limit the number of tokens (basic units like words or characters) generated by the model.
If max_tokens is set, the model will stop generating text once it reaches the specified limit.

#### Top_k:

This parameter controls the number of top tokens the model considers at each generation step.

For instance, if top_k is set to 5, the model only considers the five tokens with the highest probabilities for the next generation step.

Example request :
```http
  POST http://localhost:8000/answer_question
```

This is sample body request (JSON) for this API
```http
{
  "question": "Apa itu pulau bali?",
  "temperature": 0.7,
  "max_tokens": 128,
  "top_k": 50
}
```

or curl command :
```http
curl -X 'POST' \
  'http://127.0.0.1:8000/answer_question' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "question": "Apa itu pulau bali?",
  "temperature": 0.7,
  "max_tokens": 128,
  "top_k": 50
}'
```
## Screenshots

#### API (Swagger UI) 

![App Screenshot](/images/swagger_ui.png)

#### Running Test

![App Screenshot](/images/running_test.png)
## Tech Stack

python, langchain, fastapi, together ai

